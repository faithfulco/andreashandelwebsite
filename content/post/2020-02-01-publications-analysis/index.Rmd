---
title: Using R to analyze publications
subtitle: 
summary: Some code and examples showing how to process and analyze meta-data for a set of publications. Useful to get list of co-authors, etc.
author: Andreas Handel
draft: true
date: '2020-02-01'
slug: publications-analysis
categories: []
tags: []
featured: no
disable_jquery: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


```{r, include = FALSE}
#remotes::install_github('emo')
#library('emo')
```

# Overview

I needed some information on all my publications for "bean counting" purposes related to preparing my promotion materials. In the past, I also needed similar information for NSF grant applications. 

Instead of doing things by hand, there are nicer/faster ways using R. The following shows a few things one can do with the `scholar` package.

# Required packages

```{r, include = TRUE}
library(scholar)
library(dplyr)
library(tidyr)
library(knitr)
library(ggplot2)
library(here)
library(bibliometrix)
```

# Getting all citations for one (or more) individuals

```{r}
#Define the person to analyze
scholar_ids="bruHK0YAAAAJ" #could be more than one ID
cites = compare_scholar_careers(scholar_ids, career = TRUE) #get citations
```

# Compare citations for different time periods

For my purpose, I want to compare citations between 2 time periods (my Assistant Professor time and my Associate Professor time). I'm splitting them into 2.

```{r}
#define who to analyze. Really only needed if more than 1 person's information is pulled above.
scholar_id = scholar_ids[1] 
period_1_start = 2009
period_2_start = 2015
cites_1 <- cites %>% dplyr::filter(id == scholar_id, (year>=period_1_start & year<period_2_start ))
cites_2 <- cites %>% dplyr::filter(id == scholar_id, (year>=period_2_start & year<2020 )) #remove last year since it's not a full year
```

Fitting a linear model to both time segments to look at increase in citations over both periods.
```{r}
fit1=lm(cites ~ year, data = cites_1)
fit2=lm(cites ~ year, data = cites_2)
inc1 = fit1$coefficients["year"]
inc2 = fit2$coefficients["year"] 
print(sprintf('Annual increase for periods 1 and 2 are %f, %f',inc1,inc2))
```

Making a figure to show citation count increases

```{r}
# combine data above into single data frame
#add a variable to indicate period 1 and period 2
cites_1$group = "1"
cites_2$group = "2"
cites_df = rbind(cites_1,cites_2)

#make the plot and show linear fit lines
p1 <- ggplot(data = cites_df, aes(year, cites, colour=group, shape=group)) + geom_point(size = I(4)) + geom_smooth(method="lm",aes(group = group), se = F, size=1.5)  
# format axes and legend
p2 <- p1 + scale_x_continuous(name = "Year", breaks = cites_df$year, labels = cites_df$year) + scale_y_continuous("Citations according to Google Scholar") + theme_bw(base_size=14) + theme(legend.position="none") 
# add text to plot
p3 <- p2 + geom_text(aes(NULL,NULL),x=2010.8,y=150,label="Average annual \n increase 23%",color="black",size=5.5)
p4 <- p3 + geom_text(aes(NULL,NULL),x=2017,y=150,label="Average annual \n increase 45%",color="black",size=5.5) 

#open a new graphics window
#note that this is Windows specific. Use quartz() for MacOS
ww=5; wh=5; 
windows(width=ww, height=wh)					
print(p4)
dev.print(device=png,width=ww,height=wh,units="in",res=600,file="citations.png")
```

# Getting list of co-authors

```{r}
#get all pubs for an author (or multiple)

pubs <- get_publications(scholar_ids)

#here I want to separately look at publications in the 2 time periods I defined above
pubs_old <- pubs %>% dplyr::filter((year>=period_1_start & year<period_2_start ))
pubs_new <- pubs %>% dplyr::filter(year>=period_2_start)

#unfortunately, get_publications only pulls from the main page, which cuts off the author list. 
#to get all authors, one needs to run through each paper
authors_old <- sapply(pubs_old$pubid, get_complete_authors(id = scholar_ids))

```


# Making a table of journals and impact factors
```{r}
#get all pubs for an author (or multiple)
pubs <- get_publications(scholar_ids)
#here I only want publications since 2015
pubs <- pubs %>% dplyr::filter(year>2014)
ifdata <- get_impactfactor(pubs$journal) 
#sort and remove non-journal entries since Google SCholar collects all kinds of 'publications', including items other than standard peer-reviewed papers
iftable <- ifdata %>% dplyr::arrange(desc(ImpactFactor) ) %>% tidyr::drop_na()
knitr::kable(iftable)
```
Ok so this doesn't quite work. I know for instance that I didn't publish anything in _Cancer Journal for Clinicians_ and the 2 _Rheumatology_ entries are workshop presentations. Oddly, when I look at `pubs$journal` there is no Cancer Journal listed. Somehow this is a bug created by the `get_impactfactor()` function. I could fix that by hand. The bigger problem is what to do with all those publications that are not peer-reviewed papers. I could remove them from my google scholar profile. But I kind of want to keep them there since some of them link to useful stuff. I could alternatively manually clean things at this step. This somewhat defeats the purpose of automation. 
I do keep all my published, peer-reviewed papers in a bibtex bibliography file in my reference manager (I'm using Zotero and/or Jabref). I know that file is "clean" and only contains real peer-reviewed papers. Unfortunately, the `scholar` package can't read in such data.


```{r}
D <- readFiles("myrefs.bib")

```



